{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6811a4",
   "metadata": {},
   "source": [
    "# ðŸ§ª Lab 3: Use an MCP Server as a Plugin in a Semantic Kernel Agent\n",
    "\n",
    "In this lab, you'll learn how to **extend a Semantic Kernel agent** by connecting it to an **MCP server**. MCP (Model Context Protocol) allows agents to invoke external tools, services, or other agents as plugins.\n",
    "\n",
    "## ðŸŽ¯ What You'll Learn\n",
    "\n",
    "You'll specifically:\n",
    "- Connect to **your own Codebeamer MCP server** (which you built in **Lab 2**) as a tool via `MCPStreamableHttpPlugin`\n",
    "- Create a **Semantic Kernel agent** powered by Azure OpenAI\n",
    "- Use the MCP plugin inside the agent to access Codebeamer functionality\n",
    "- Interact with the agent through a chat interface\n",
    "- See the agent automatically call functions on the Codebeamer MCP server to answer questions\n",
    "\n",
    "This lab showcases how Semantic Kernel can leverage **modular, tool-augmented AI workflows** by treating external MCP servers as powerful extensions to the agent's reasoning capabilities.\n",
    "\n",
    "## âœ… Prerequisites\n",
    "\n",
    "Before starting this lab:\n",
    "1. **Complete Lab 2** - You need the Codebeamer MCP server running on `http://localhost:8080`\n",
    "2. **Azure OpenAI credentials** - Ensure your `.env` file is configured with:\n",
    "   - `AZURE_OPENAI_ENDPOINT`\n",
    "   - `AZURE_OPENAI_KEY`\n",
    "   - `MODEL_DEPLOYMENT_NAME`\n",
    "   - `MODEL_DEPLOYMENT_API_VERSION`\n",
    "3. **Start your MCP server** - Run `python3 servers/mcp_server.py` in a terminal\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949ed733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel.connectors.mcp import MCPStreamableHttpPlugin\n",
    "from semantic_kernel.agents import AzureResponsesAgent\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd647cc9",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries and Load Environment Variables\n",
    "\n",
    "First, we'll import the necessary Semantic Kernel components and load our Azure OpenAI credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc5cb060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AZURE_OPENAI_ENDPOINT: https://short-hack-ai-foundry.cognitiveservices.azure.com/\n",
      "AZURE_OPENAI_KEY: ***\n",
      "MODEL_DEPLOYMENT_NAME: gpt-4o\n",
      "MODEL_DEPLOYMENT_API_VERSION: 2025-03-01-preview\n"
     ]
    }
   ],
   "source": [
    "# Check environment variables\n",
    "print(\"AZURE_OPENAI_ENDPOINT:\", os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "print(\"AZURE_OPENAI_KEY:\", \"***\" if os.getenv(\"AZURE_OPENAI_KEY\") else \"Not set\")\n",
    "print(\"MODEL_DEPLOYMENT_NAME:\", os.getenv(\"MODEL_DEPLOYMENT_NAME\"))\n",
    "print(\"MODEL_DEPLOYMENT_API_VERSION:\", os.getenv(\"MODEL_DEPLOYMENT_API_VERSION\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7727f84",
   "metadata": {},
   "source": [
    "## Step 2: Connect to the Codebeamer MCP Server\n",
    "\n",
    "Now we'll initialize and connect to the Codebeamer MCP server using the `MCPStreamableHttpPlugin` interface.\n",
    "\n",
    "**Key points:**\n",
    "- `MCPStreamableHttpPlugin` enables connections to MCP Servers through HTTP/HTTPS\n",
    "- The URL should match your MCP server endpoint (default: `http://localhost:8080/mcp`)\n",
    "- **Important:** Make sure the MCP server built in Lab 2 is running before executing this cell!\n",
    "\n",
    "Run `python3 servers/mcp_server.py` in a separate terminal if you haven't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca2a8a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m codebeamer_plugin = MCPStreamableHttpPlugin(\n\u001b[32m      2\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mCodebeamer\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     description=\u001b[33m\"\u001b[39m\u001b[33mCodebeamer Plugin\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     url=\u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:8080/mcp\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Start the connection to the MCP plugin\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m codebeamer_plugin.connect()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/short-hack-20251113/SHORTHACK-MCP/venv/lib/python3.11/site-packages/semantic_kernel/connectors/mcp.py:243\u001b[39m, in \u001b[36mMCPPluginBase.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    242\u001b[39m     \u001b[38;5;28mself\u001b[39m._current_task = asyncio.create_task(\u001b[38;5;28mself\u001b[39m._inner_connect(ready_event))\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m ready_event.wait()\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m KernelPluginInvalidConfigurationError:\n\u001b[32m    245\u001b[39m     ready_event.clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/locks.py:213\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "codebeamer_plugin = MCPStreamableHttpPlugin(\n",
    "    name=\"Codebeamer\",\n",
    "    description=\"Codebeamer Plugin\",\n",
    "    url=\"http://localhost:8080/mcp\",\n",
    ")\n",
    "\n",
    "# Start the connection to the MCP plugin\n",
    "await codebeamer_plugin.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c9c81b",
   "metadata": {},
   "source": [
    "## Step 3: Create the Azure OpenAI Client and Semantic Kernel Agent\n",
    "\n",
    "In this step, we'll:\n",
    "1. **Create an Azure OpenAI client** using our credentials\n",
    "2. **Initialize a Semantic Kernel agent** (`AzureResponsesAgent`) that:\n",
    "   - Uses Azure OpenAI for language understanding\n",
    "   - Has access to the Codebeamer MCP plugin\n",
    "   - Can automatically invoke Codebeamer tools when needed\n",
    "\n",
    "The agent's instructions define its behavior and capabilities. Feel free to customize these instructions for your use case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d59fff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Semantic Kernel agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create the Azure OpenAI client using credentials from environment variables\n",
    "client = AzureResponsesAgent.create_client(\n",
    "    deployment_name=os.getenv(\"MODEL_DEPLOYMENT_NAME\"),\n",
    "    api_version=os.getenv(\"MODEL_DEPLOYMENT_API_VERSION\"),\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    ")\n",
    "\n",
    "# Create the Semantic Kernel agent with the MCP plugin\n",
    "codebeamer_agent = AzureResponsesAgent(\n",
    "    ai_model_id=os.getenv(\"MODEL_DEPLOYMENT_NAME\"),\n",
    "    client=client,\n",
    "    name=\"CodebeamerAgent\",\n",
    "    description=\"A chat bot that helps users interact with Codebeamer.\",\n",
    "    instructions=\"\"\"\n",
    "You are a helpful assistant that can interact with Codebeamer through the provided tools.\n",
    "You can help users:\n",
    "- List and explore projects\n",
    "- View and manage trackers\n",
    "- Get information about tracker items\n",
    "- Read and post comments\n",
    "When a user asks about Codebeamer data, use the available tools to fetch the information.\n",
    "Provide clear, concise, and helpful responses.\n",
    "\"\"\",\n",
    "    plugins=[codebeamer_plugin],\n",
    ")\n",
    "\n",
    "print(\"âœ… Semantic Kernel agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6577477",
   "metadata": {},
   "source": [
    "## Step 4: Chat with Your Agent\n",
    "\n",
    "Now let's run an interactive chat loop! The agent will:\n",
    "- Receive your questions\n",
    "- Automatically decide when to call Codebeamer MCP tools\n",
    "- Maintain conversation context across multiple messages\n",
    "- Provide intelligent responses based on the data retrieved\n",
    "\n",
    "**Try these example questions:**\n",
    "- \"What projects are available?\"\n",
    "- \"Show me the trackers for project ID 12345\"\n",
    "- \"Get items from tracker 5001\"\n",
    "- \"What are the comments on item 5881865?\"\n",
    "- \"Post a comment saying 'Looking good!' on item 5881865\"\n",
    "\n",
    "Type `exit` or `quit` to end the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0aa4346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ Starting chat with Codebeamer Agent...\n",
      "Type 'exit' or 'quit' to end the conversation.\n",
      "\n",
      "Bot: Let me retrieve all the projects in Codebeamer for you. One moment!\n",
      "\n",
      "Goodbye! ðŸ‘‹\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "Cancelled via cancel scope 15caa9950",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mWouldBlock\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/short-hack-20251113/SHORTHACK-MCP/venv/lib/python3.11/site-packages/anyio/streams/memory.py:111\u001b[39m, in \u001b[36mMemoryObjectReceiveStream.receive\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreceive_nowait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m WouldBlock:\n\u001b[32m    113\u001b[39m     \u001b[38;5;66;03m# Add ourselves in the queue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/short-hack-20251113/SHORTHACK-MCP/venv/lib/python3.11/site-packages/anyio/streams/memory.py:106\u001b[39m, in \u001b[36mMemoryObjectReceiveStream.receive_nowait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EndOfStream\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m WouldBlock\n",
      "\u001b[31mWouldBlock\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m     thread = response.thread\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Clean up the connection\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m codebeamer_plugin.close()\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Connection closed.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/short-hack-20251113/SHORTHACK-MCP/venv/lib/python3.11/site-packages/semantic_kernel/connectors/mcp.py:260\u001b[39m, in \u001b[36mMCPPluginBase.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    257\u001b[39m     \u001b[38;5;28mself\u001b[39m._stop_event.set()\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._current_task:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# After, the signal, we wait for it to close the exit stack.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._current_task\n\u001b[32m    261\u001b[39m     \u001b[38;5;28mself\u001b[39m._current_task = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    262\u001b[39m \u001b[38;5;28mself\u001b[39m.session = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/short-hack-20251113/SHORTHACK-MCP/venv/lib/python3.11/site-packages/semantic_kernel/connectors/mcp.py:291\u001b[39m, in \u001b[36mMCPPluginBase._inner_connect\u001b[39m\u001b[34m(self, ready_event)\u001b[39m\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m KernelPluginInvalidConfigurationError(\n\u001b[32m    288\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to create a session. Please check your configuration.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    289\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m session.initialize()\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exit_stack.aclose()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/short-hack-20251113/SHORTHACK-MCP/venv/lib/python3.11/site-packages/mcp/client/session.py:153\u001b[39m, in \u001b[36mClientSession.initialize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    141\u001b[39m elicitation = (\n\u001b[32m    142\u001b[39m     types.ElicitationCapability() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._elicitation_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _default_elicitation_callback \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    143\u001b[39m )\n\u001b[32m    144\u001b[39m roots = (\n\u001b[32m    145\u001b[39m     \u001b[38;5;66;03m# TODO: Should this be based on whether we\u001b[39;00m\n\u001b[32m    146\u001b[39m     \u001b[38;5;66;03m# _will_ send notifications, or only whether\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    151\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send_request(\n\u001b[32m    154\u001b[39m     types.ClientRequest(\n\u001b[32m    155\u001b[39m         types.InitializeRequest(\n\u001b[32m    156\u001b[39m             params=types.InitializeRequestParams(\n\u001b[32m    157\u001b[39m                 protocolVersion=types.LATEST_PROTOCOL_VERSION,\n\u001b[32m    158\u001b[39m                 capabilities=types.ClientCapabilities(\n\u001b[32m    159\u001b[39m                     sampling=sampling,\n\u001b[32m    160\u001b[39m                     elicitation=elicitation,\n\u001b[32m    161\u001b[39m                     experimental=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    162\u001b[39m                     roots=roots,\n\u001b[32m    163\u001b[39m                 ),\n\u001b[32m    164\u001b[39m                 clientInfo=\u001b[38;5;28mself\u001b[39m._client_info,\n\u001b[32m    165\u001b[39m             ),\n\u001b[32m    166\u001b[39m         )\n\u001b[32m    167\u001b[39m     ),\n\u001b[32m    168\u001b[39m     types.InitializeResult,\n\u001b[32m    169\u001b[39m )\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.protocolVersion \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_PROTOCOL_VERSIONS:\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported protocol version from the server: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.protocolVersion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/short-hack-20251113/SHORTHACK-MCP/venv/lib/python3.11/site-packages/mcp/shared/session.py:272\u001b[39m, in \u001b[36mBaseSession.send_request\u001b[39m\u001b[34m(self, request, result_type, request_read_timeout_seconds, metadata, progress_callback)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m         response_or_error = \u001b[38;5;28;01mawait\u001b[39;00m response_stream_reader.receive()\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m McpError(\n\u001b[32m    275\u001b[39m         ErrorData(\n\u001b[32m    276\u001b[39m             code=httpx.codes.REQUEST_TIMEOUT,\n\u001b[32m   (...)\u001b[39m\u001b[32m    282\u001b[39m         )\n\u001b[32m    283\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/short-hack-20251113/SHORTHACK-MCP/venv/lib/python3.11/site-packages/anyio/streams/memory.py:119\u001b[39m, in \u001b[36mMemoryObjectReceiveStream.receive\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._state.waiting_receivers[receive_event] = receiver\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m receive_event.wait()\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28mself\u001b[39m._state.waiting_receivers.pop(receive_event, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/locks.py:213\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: Cancelled via cancel scope 15caa9950"
     ]
    }
   ],
   "source": [
    "# Create the thread - starts as None, will be set after first response\n",
    "thread = None\n",
    "\n",
    "print(\"ðŸ’¬ Starting chat with Codebeamer Agent...\")\n",
    "print(\"Type 'exit' or 'quit' to end the conversation.\\n\")\n",
    "\n",
    "# Run the agent as a chat\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Goodbye! ðŸ‘‹\")\n",
    "        break\n",
    "\n",
    "    # Get response from the agent\n",
    "    response = await codebeamer_agent.get_response(\n",
    "        messages=user_input,\n",
    "        thread=thread,\n",
    "    )\n",
    "\n",
    "    # Print the response\n",
    "    print(f\"Bot: {response.content}\\n\")\n",
    "    \n",
    "    # Update the thread with the response to maintain conversation context\n",
    "    thread = response.thread\n",
    "\n",
    "# Clean up the connection\n",
    "await codebeamer_plugin.close()\n",
    "print(\"âœ… Connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71784718",
   "metadata": {},
   "source": [
    "## ðŸŽ“ What You Learned\n",
    "\n",
    "Congratulations! In this lab, you've successfully:\n",
    "\n",
    "âœ… Connected a Semantic Kernel agent to an external MCP server  \n",
    "âœ… Created a tool-augmented AI agent with Azure OpenAI  \n",
    "âœ… Enabled automatic tool selection and invocation  \n",
    "âœ… Built an interactive chat interface with conversation context  \n",
    "âœ… Integrated custom APIs (Codebeamer) into an AI workflow  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Next Steps & Exploration\n",
    "\n",
    "### Extend Your Agent\n",
    "\n",
    "You can now:\n",
    "- **Add more MCP plugins** - Connect multiple MCP servers to create a multi-tool agent\n",
    "- **Customize instructions** - Tailor the agent's behavior for specific use cases\n",
    "- **Build workflows** - Chain multiple tool calls together for complex tasks\n",
    "- **Add memory** - Implement persistent conversation history\n",
    "\n",
    "### Explore Other MCP Servers\n",
    "\n",
    "The real power comes from the flexibility of MCP plugins in Semantic Kernel. You can connect to **any tool that implements the Model Context Protocol (MCP)**.\n",
    "\n",
    "ðŸ§° **Explore These MCP Servers:**\n",
    "\n",
    "- ðŸ”— [Official MCP Server Integrations (GitHub)](https://github.com/modelcontextprotocol/servers?tab=readme-ov-file#%EF%B8%8F-official-integrations)  \n",
    "  A growing list of plugins including GitHub, Slack, Google Drive, PostgreSQL, and more.\n",
    "\n",
    "- ðŸ“š [10 Must-Know MCP Servers for Developers (DevShorts)](https://www.devshorts.in/p/ten-must-know-mcp-servers-for-every?utm_source=chatgpt.com)  \n",
    "  A curated blog post with descriptions, commands, and usage tips.\n",
    "\n",
    "- ðŸ”§ [FastMCP Documentation](https://gofastmcp.com/)  \n",
    "  Learn more about building your own MCP servers.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Key Concepts Recap\n",
    "\n",
    "### MCPStreamableHttpPlugin\n",
    "- Enables Semantic Kernel to connect to MCP servers via HTTP\n",
    "- Handles tool discovery and invocation automatically\n",
    "- Supports async operations for better performance\n",
    "\n",
    "### AzureResponsesAgent\n",
    "- A Semantic Kernel agent powered by Azure OpenAI\n",
    "- Can accept multiple plugins for tool augmentation\n",
    "- Maintains conversation context with threads\n",
    "- Automatically decides when to invoke tools\n",
    "\n",
    "### Tool-Augmented AI\n",
    "- LLMs can be extended with external tools and APIs\n",
    "- MCP provides a standardized protocol for tool integration\n",
    "- Agents can reason about when and how to use tools\n",
    "- This enables AI to interact with real-world systems and data\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’¡ Challenge Ideas\n",
    "\n",
    "Try these extensions to deepen your understanding:\n",
    "\n",
    "1. **Multi-Plugin Agent**: Add the Wikipedia MCP server from Lab 1 alongside Codebeamer\n",
    "2. **Custom Instructions**: Modify the agent to specialize in specific Codebeamer workflows\n",
    "3. **Error Handling**: Add try-catch blocks and graceful error messages\n",
    "4. **Logging**: Track which tools are called and why\n",
    "5. **Build Your Own**: Create a completely new MCP server and integrate it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
